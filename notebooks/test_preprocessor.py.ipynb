{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feab3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83862c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# https://teddykoker.com/2020/12/dataloader/\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/rkube/repos/frnn-loader\")\n",
    "\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "\n",
    "from frnn_loader.backends.fetchers import fetcher_d3d_v1\n",
    "from frnn_loader.backends.backend_hdf5 import backend_hdf5\n",
    "from frnn_loader.primitives.filters import filter_ip_thresh\n",
    "from frnn_loader.primitives.resamplers import resampler_causal\n",
    "from frnn_loader.primitives.signal import signal_0d\n",
    "from frnn_loader.primitives.normalizers import mean_std_normalizer\n",
    "from frnn_loader.loaders.frnn_dataset_disk import shot_dataset_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2464bbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Construct a dataset for FRNN training.\\n\\nPredictive machine learning models are trained on datasets. These dataset\\nconsist of a suite of measurements taken on a set of shots.\\n\\nDeep neural networks are trained on pre-processed and normalized data.\\nPre-processing includes:\\n- Resampling of the measurements onto a common time-base\\n- Construction of target variables, such as time-to-disruption or time-to-ELM\\n- Signal clipping\\n\\nNormalization means the transformation of signals into order unity quantities. Common ways\\nto do this is by a Z-score transformation (subtract mean, divide by std dev.), min/max normalizer,\\netc.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Construct a dataset for FRNN training.\n",
    "\n",
    "Predictive machine learning models are trained on datasets. These dataset\n",
    "consist of a suite of measurements taken on a set of shots.\n",
    "\n",
    "Deep neural networks are trained on pre-processed and normalized data.\n",
    "Pre-processing includes:\n",
    "- Resampling of the measurements onto a common time-base\n",
    "- Construction of target variables, such as time-to-disruption or time-to-ELM\n",
    "- Signal clipping\n",
    "\n",
    "Normalization means the transformation of signals into order unity quantities. Common ways\n",
    "to do this is by a Z-score transformation (subtract mean, divide by std dev.), min/max normalizer,\n",
    "etc.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "061fad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where all project data files are to be stored\n",
    "proj_dir = \"/projects/FRNN/frnn_loader\"\n",
    "\n",
    "# 1/ Describe the dataset\n",
    "predictor_tags = [\n",
    "    \"q95\",\n",
    "    \"efsli\",\n",
    "    \"ipspr15V\",\n",
    "    \"efsbetan\",\n",
    "    \"efswmhd\",\n",
    "    \"dusbradial\",\n",
    "    \"dssdenest\",\n",
    "    \"pradcore\",\n",
    "    \"pradedge\",\n",
    "    \"bmspinj\",\n",
    "    \"bmstinj\",\n",
    "    \"ipsiptargt\",\n",
    "    \"ipeecoil\",\n",
    "]\n",
    "predictor_list = [signal_0d(tag) for tag in predictor_tags]\n",
    "\n",
    "# Contains a list of shots that are non-disruptive\n",
    "shotlist_clear = \"d3d_clear_100.txt\"\n",
    "# Contains a list of shots that are disruptive\n",
    "shotlist_disrupt = \"d3d_disrupt_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d7cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the filter we use to crimp the shot times\n",
    "ip_filter = filter_ip_thresh(0.2)\n",
    "signal_ip = signal_0d(\"ipspr15V\")\n",
    "my_backend = backend_hdf5(proj_dir)\n",
    "my_fetcher = fetcher_d3d_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e7bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots = 5\n",
    "shotdict = {}\n",
    "\n",
    "i = 0\n",
    "with open(join(proj_dir, \"..\", \"shot_lists\", shotlist_clear), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "\n",
    "        # Run the Ip filter over the current shot\n",
    "        tb, data = my_backend.load(signal_ip.info, shotnr)\n",
    "        tmin, tmax = ip_filter(tb, data)\n",
    "        shotdict.update(\n",
    "            {\n",
    "                shotnr: {\n",
    "                    \"tmin\": tmin,\n",
    "                    \"tmax\": tmax,\n",
    "                    \"is_disruptive\": False,\n",
    "                    \"t_disrupt\": -1.0,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        if i >= num_shots:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba1d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shotdict =  {167475: {'tmin': 37.75, 'tmax': 6233.25, 'is_disruptive': False, 't_disrupt': -1.0}, 167481: {'tmin': 30.5, 'tmax': 6455.25, 'is_disruptive': False, 't_disrupt': -1.0}, 167482: {'tmin': 34.0, 'tmax': 6445.25, 'is_disruptive': False, 't_disrupt': -1.0}, 167483: {'tmin': 37.0, 'tmax': 6842.25, 'is_disruptive': False, 't_disrupt': -1.0}, 167484: {'tmin': 37.5, 'tmax': 6245.0, 'is_disruptive': False, 't_disrupt': -1.0}, 167480: {'tmin': 37.5, 'tmax': 5073.5, 'is_disruptive': True, 't_disrupt': 5073.5}, 167487: {'tmin': 37.5, 'tmax': 2159.0, 'is_disruptive': True, 't_disrupt': 2159.0}, 167488: {'tmin': 37.5, 'tmax': 5269.0, 'is_disruptive': True, 't_disrupt': 5269.0}, 167492: {'tmin': 37.5, 'tmax': 7088.0, 'is_disruptive': True, 't_disrupt': 7088.0}, 167494: {'tmin': 37.5, 'tmax': 3478.5, 'is_disruptive': True, 't_disrupt': 3478.5}}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with open(join(proj_dir, \"..\", \"shot_lists\", shotlist_disrupt), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "        # ttd is given in seconds in the text files. Convert it to milliseconds\n",
    "        ttd = ttd * 1e3\n",
    "        shotdict.update(\n",
    "            {\n",
    "                shotnr: {\n",
    "                    \"tmin\": tmin,\n",
    "                    \"tmax\": ttd,\n",
    "                    \"is_disruptive\": True,\n",
    "                    \"t_disrupt\": ttd,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        if i >= num_shots:\n",
    "            break\n",
    "\n",
    "print(\"shotdict = \", shotdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "636de3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167475\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167481\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167482\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167483\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167484\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167480\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167487\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167488\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167492\n",
      "__init__: root = /projects/FRNN/frnn_loader\n",
      "167494\n",
      "__init__: root = /projects/FRNN/frnn_loader\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "#\n",
    "# Next we create a list of datasets for all shots.\n",
    "# The shots are cut to the time intervals defined by tmin and tmax\n",
    "# No transformation has been defined,\n",
    "\n",
    "dset_list = []\n",
    "for shotnr in shotdict.keys():\n",
    "    print(shotnr)\n",
    "\n",
    "    # Resample all signals over the valid intervals\n",
    "    my_resampler = resampler_causal(0.0, shotdict[shotnr][\"tmax\"], 1.0)\n",
    "\n",
    "    ds = shot_dataset_disk(\n",
    "        shotnr,\n",
    "        predictors=predictor_list,\n",
    "        resampler=my_resampler,\n",
    "        backend_file=my_backend,\n",
    "        fetcher=my_fetcher,\n",
    "        root=proj_dir,\n",
    "        download=True,\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    dset_list.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9cf6005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#\n",
    "# With all datasets cropped to the correct time in place we continue by calculating the normalization.\n",
    "# Do this using multi-processing\n",
    "my_normalizer = mean_std_normalizer()\n",
    "my_normalizer.fit(dset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94ea263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_normalizer.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb267c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.2881e+00,  1.0096e+00,  1.7226e+00,  1.6998e+00,  5.6891e+05,\n",
       "         9.0436e-01,  3.2198e+00,  1.5518e-03,  1.3113e-03,  5.0626e+03,\n",
       "         4.0367e+00,  1.7478e+00, -2.8650e-02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_normalizer.mean_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0ba5a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8086e+00, 3.4762e-01, 4.5560e-01, 1.0277e+00, 3.6443e+05, 1.0497e+00,\n",
       "        1.3093e+00, 1.9447e-03, 1.0103e-03, 3.3218e+03, 2.7402e+00, 4.6416e-01,\n",
       "        1.1235e-01])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_normalizer.std_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f2490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6234, 13]) tensor([-0.0267, -0.0952,  0.0347,  0.1136,  0.1621, -0.0045, -0.1391,  0.1717,\n",
      "         0.0775,  0.1645,  0.1270,  0.0469, -0.0595]) tensor([0.7978, 1.0978, 0.9519, 0.9931, 1.0204, 0.9509, 0.8209, 0.8511, 0.9136,\n",
      "        1.0144, 0.9674, 0.8824, 0.7272])\n",
      "torch.Size([6456, 13]) tensor([ 0.0234, -0.1454, -0.0376,  0.0219,  0.0647,  0.1862,  0.2429,  0.3585,\n",
      "        -0.1759,  0.3616,  0.3748, -0.0572,  0.0820]) tensor([0.7518, 0.9331, 1.0060, 1.0907, 1.0695, 0.9223, 1.1449, 1.1887, 0.7864,\n",
      "        1.3123, 1.3134, 1.0297, 0.3068])\n",
      "torch.Size([6446, 13]) tensor([-0.0311, -0.0795, -0.0192,  0.0953,  0.1292,  0.1281,  0.0173,  0.2036,\n",
      "        -0.0305,  0.3278,  0.3510, -0.0523,  0.1358]) tensor([0.7493, 1.1101, 0.9920, 1.1733, 1.1274, 0.9080, 0.9154, 1.1008, 0.8759,\n",
      "        1.2848, 1.2854, 1.0226, 0.2710])\n",
      "torch.Size([6843, 13]) tensor([ 0.0513, -0.0568, -0.1926,  0.1774,  0.2087,  0.2226, -0.1236, -0.2423,\n",
      "         0.3224, -0.1173, -0.1194, -0.2677,  0.3227]) tensor([0.8320, 1.2756, 1.2025, 1.2064, 1.1867, 1.5026, 0.9401, 0.3484, 1.2093,\n",
      "        0.9357, 0.9211, 1.3181, 0.6837])\n",
      "torch.Size([6245, 13]) tensor([-0.0685,  0.5314, -0.0918, -0.4718, -0.4350,  0.0445, -0.5812, -0.3093,\n",
      "        -0.1666, -0.4673, -0.4516, -0.1079,  0.0682]) tensor([0.9336, 1.2690, 1.0375, 0.9556, 0.9155, 1.1005, 0.8481, 0.3452, 0.8509,\n",
      "        0.7604, 0.7538, 1.0750, 0.2986])\n",
      "torch.Size([5074, 13]) tensor([ 0.0023, -0.1074,  0.2156,  0.3571,  0.4140, -0.3205,  0.1143, -0.0122,\n",
      "         0.2074,  0.1795,  0.1719,  0.1813,  0.1136]) tensor([0.8085, 0.3065, 0.7346, 0.9522, 0.9827, 0.4422, 0.8565, 0.7737, 0.9177,\n",
      "        0.7511, 0.7522, 0.7701, 0.2857])\n",
      "torch.Size([2159, 13]) tensor([ 0.5206,  0.5399, -0.2903, -0.3747, -0.3824, -0.2182, -0.3401, -0.1787,\n",
      "        -0.4632, -0.4734, -0.4975, -0.2151, -0.3175]) tensor([1.9811, 0.9871, 1.1816, 0.9350, 0.8860, 0.5958, 1.1274, 1.3088, 0.8793,\n",
      "        0.7977, 0.7803, 1.1326, 0.7560])\n",
      "torch.Size([5269, 13]) tensor([-0.0950,  0.1975,  0.1606,  0.1310,  0.1540,  0.1332,  0.3389,  0.1359,\n",
      "         0.1445,  0.1567,  0.1475,  0.1822, -0.1015]) tensor([0.6190, 0.6597, 0.8092, 0.7001, 0.7468, 0.5269, 1.0023, 0.8315, 0.8061,\n",
      "        0.7298, 0.7319, 0.7969, 0.3719])\n",
      "torch.Size([7088, 13]) tensor([-0.4398, -0.2648,  0.3547,  0.0587, -0.0434, -0.3371,  0.2323, -0.3481,\n",
      "         0.5109,  0.0707,  0.1308,  0.3026,  0.2185]) tensor([0.6613, 0.6952, 0.7764, 0.7805, 0.7792, 0.5172, 0.7738, 0.1985, 1.1427,\n",
      "        1.0273, 1.0720, 0.7518, 0.4352])\n",
      "torch.Size([3479, 13]) tensor([ 0.0637, -0.5198, -0.1341, -0.1086, -0.2720,  0.1656,  0.2382,  0.2210,\n",
      "        -0.4266, -0.2027, -0.2346, -0.0124, -0.4624]) tensor([0.8889, 0.6818, 1.0175, 0.7898, 0.8288, 1.5641, 1.0872, 1.6720, 1.0645,\n",
      "        0.7303, 0.7372, 0.9235, 2.6918])\n"
     ]
    }
   ],
   "source": [
    "# Now we can add the normalizer as a transform. The __getitem__ method of the dataset\n",
    "# will apply the transform.\n",
    "\n",
    "# Verify that the returned data is about zero mean and order unity std deviation\n",
    "for ds in dset_list:\n",
    "    ds.transform = my_normalizer\n",
    "\n",
    "    print(ds[:].shape, ds[:].mean(axis=0), ds[:].std(axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22f27b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected signals (determines which signals are used for training):\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "my_conf = parse_config(\"conf_test_preprocessor.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14123ba8",
   "metadata": {},
   "source": [
    "# Paths\n",
    "\n",
    "The basis path where all data is searched for is given by conf[\"paths\"][\"fs_path\"]. \n",
    "\n",
    "Directories that are searched for signals are given by conf[\"paths\"][\"signal_prepath\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb0976f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callbacks': {'list': ['earlystop'],\n",
       "  'metrics': ['val_loss', 'val_roc', 'train_loss'],\n",
       "  'mode': 'min',\n",
       "  'monitor': 'val_loss',\n",
       "  'patience': 50,\n",
       "  'write_grads': False},\n",
       " 'data': {'T_max': 1000.0,\n",
       "  'T_min_warn': 30,\n",
       "  'T_warning': 30,\n",
       "  'augment_during_training': False,\n",
       "  'augmentation_mode': 'none',\n",
       "  'bleed_in': 0,\n",
       "  'bleed_in_remove_from_test': True,\n",
       "  'current_end_thresh': 10000,\n",
       "  'current_index': 0,\n",
       "  'current_thresh': 750000,\n",
       "  'cut_shot_ends': False,\n",
       "  'dt': 0.001,\n",
       "  'equalize_classes': False,\n",
       "  'floatx': 'float32',\n",
       "  'normalizer': 'var',\n",
       "  'plotting': False,\n",
       "  'positive_example_penalty': 16.0,\n",
       "  'recompute': False,\n",
       "  'recompute_normalization': False,\n",
       "  'signal_to_augment': 'None',\n",
       "  'use_shots': 200000,\n",
       "  'window_decay': 2,\n",
       "  'window_size': 10,\n",
       "  'target': plasma.models.targets.FLATTarget},\n",
       " 'env': {'name': 'torch-env', 'type': 'anaconda3'},\n",
       " 'model': {'PCS': True,\n",
       "  'backend': 'tensorflow',\n",
       "  'cell_order': 4,\n",
       "  'cell_rank': 11,\n",
       "  'cell_steps': 5,\n",
       "  'clipnorm': 10.0,\n",
       "  'dense_layers_1d': 1,\n",
       "  'dense_regularization': 0.01,\n",
       "  'dense_size': 200,\n",
       "  'dense_size_1d': 32,\n",
       "  'dropout_prob': 0.03,\n",
       "  'ignore_timesteps': 100,\n",
       "  'kernel_size_spatial': 1,\n",
       "  'kernel_size_temporal': 13,\n",
       "  'length': 200,\n",
       "  'loss_scale_factor': 1,\n",
       "  'lr': 0.000214020274414051,\n",
       "  'lr_decay': 0.97,\n",
       "  'lr_decay_factor': 1.2,\n",
       "  'lr_decay_patience': 6,\n",
       "  'model_type': 'LSTM',\n",
       "  'num_conv_filters': 32,\n",
       "  'num_conv_layers': 3,\n",
       "  'optimizer': 'adam',\n",
       "  'pool_size': 2,\n",
       "  'pred_batch_size': 8,\n",
       "  'pred_length': 100,\n",
       "  'profile_cut_size': 80,\n",
       "  'regularization': 0.0,\n",
       "  'return_sequences': True,\n",
       "  'rnn_layers': 1,\n",
       "  'rnn_size': 48,\n",
       "  'rnn_type': 'LSTM',\n",
       "  'shallow': False,\n",
       "  'shallow_model': {'C': 1.0,\n",
       "   'kernel': 'rbf',\n",
       "   'learning_rate': 0.1,\n",
       "   'max_depth': 3,\n",
       "   'n_estimators': 100,\n",
       "   'num_samples': 1000000,\n",
       "   'scale_pos_weight': 10.0,\n",
       "   'skip_train': False,\n",
       "   'type': 'xgboost'},\n",
       "  'simple_conv': True,\n",
       "  'size_conv_filters': 3,\n",
       "  'skip': 1,\n",
       "  'stateful': True,\n",
       "  'tcn_hidden': 40,\n",
       "  'tcn_layers': 10,\n",
       "  'torch': True,\n",
       "  'tt_lstm_hidden': 17,\n",
       "  'warmup_steps': 0},\n",
       " 'num_gpus': 4,\n",
       " 'paths': {'data': 'd3d_data_ped_spec',\n",
       "  'executable': 'torch_learn.py',\n",
       "  'shallow_executable': 'learn.py',\n",
       "  'base_path': '/tigress',\n",
       "  'shot_list_dir': '/tigress/FRNN/shot_lists/',\n",
       "  'signal_prepath': ['/tigress/FRNN/signal_data_ipsip/',\n",
       "   '/tigress/FRNN/signal_data_new_nov2019/',\n",
       "   '/tigress/FRNN/signal_data_new_2020/',\n",
       "   '/tigress/FRNN/signal_data_new_2021/',\n",
       "   '/tigress/FRNN/signal_data_new_REAL_TIME/',\n",
       "   '/tigress/FRNN/signal_data/',\n",
       "   '/tigress/FRNN/signal_data_efit/'],\n",
       "  'global_normalizer_path': '/normalization/normalization_signal_group_184694441437167251751036554375425130447.npz',\n",
       "  'normalizer_path': './normalization/normalization_signal_group_184694441437167251751036554375425130447.npz',\n",
       "  'model_save_path': 'model_checkpoints',\n",
       "  'csvlog_save_path': 'csv_logs',\n",
       "  'results_prepath': 'results',\n",
       "  'saved_shotlist_path': '/tigress/processed_shotlists_torch',\n",
       "  'processed_prepath': '/tigress/../FRNN/rkube-temp/processed_shots_torch/signal_group_{h}',\n",
       "  'all_signals_dict': {'qmin': Minimum safety factor,\n",
       "   'n1_rms': n1 finite frequency signals,\n",
       "   'n2_rms_10': n2 finite frequency signals_10ms,\n",
       "   'n3_rms_10': n3 finite frequency signals_10ms,\n",
       "   'q95': q95 safety factor,\n",
       "   'li': internal inductance,\n",
       "   'ip': plasma current,\n",
       "   'betan': Normalized Beta,\n",
       "   'energy': stored energy,\n",
       "   'lm': Locked mode amplitude,\n",
       "   'dens': Plasma density,\n",
       "   'pradcore': Radiated Power Core,\n",
       "   'fs07': filterscope fs07,\n",
       "   'pradedge': Radiated Power Edge,\n",
       "   'pradtot': Radiated Power,\n",
       "   'pin': Input Power (beam for d3d),\n",
       "   'torquein': Input Beam Torque,\n",
       "   'neped': neped,\n",
       "   'teped': teped,\n",
       "   'newid': newid,\n",
       "   'peped': peped,\n",
       "   'tewid': tewid,\n",
       "   'iptarget': plasma current target,\n",
       "   'etemp_profile': Electron temperature profile,\n",
       "   'edens_profile': Electron density profile,\n",
       "   'mpi66m322d_spec_profile': mpi66m322d_spectrogram,\n",
       "   'qpsi_efitrt1': q profile efitrt1},\n",
       "  'shot_files': [machine: d3d\n",
       "   d3d data since shot 125500],\n",
       "  'shot_files_test': [],\n",
       "  'use_signals_dict': {'q95': q95 safety factor,\n",
       "   'qpsi_efitrt1': q profile efitrt1,\n",
       "   'fs07': filterscope fs07,\n",
       "   'neped': neped,\n",
       "   'peped': peped,\n",
       "   'newid': newid,\n",
       "   'teped': teped,\n",
       "   'tewid': tewid,\n",
       "   'ip': plasma current,\n",
       "   'lm': Locked mode amplitude,\n",
       "   'betan': Normalized Beta,\n",
       "   'energy': stored energy,\n",
       "   'dens': Plasma density,\n",
       "   'pradcore': Radiated Power Core,\n",
       "   'pradedge': Radiated Power Edge,\n",
       "   'pin': Input Power (beam for d3d),\n",
       "   'torquein': Input Beam Torque,\n",
       "   'etemp_profile': Electron temperature profile,\n",
       "   'edens_profile': Electron density profile,\n",
       "   'mpi66m322d_spec_profile': mpi66m322d_spectrogram,\n",
       "   'n1_rms': n1 finite frequency signals},\n",
       "  'use_signals': None,\n",
       "  'all_signals': None,\n",
       "  'shot_files_all': [machine: d3d\n",
       "   d3d data since shot 125500],\n",
       "  'all_machines': {d3d}},\n",
       " 'target': 'flat',\n",
       " 'training': {'as_array_of_shots': True,\n",
       "  'batch_generator_warmup_steps': 0,\n",
       "  'batch_size': 8,\n",
       "  'data_parallel': False,\n",
       "  'hyperparam_tuning': True,\n",
       "  'max_patch_length': 100000,\n",
       "  'num_batches_minimum': 200,\n",
       "  'num_epochs': 1000,\n",
       "  'num_shots_at_once': 200,\n",
       "  'predict_mode': 'ttelm_target',\n",
       "  'predict_time': 1,\n",
       "  'ranking_difficulty_fac': 1.0,\n",
       "  'restart': False,\n",
       "  'shuffle_training': True,\n",
       "  'target_description': ['filterscope fs07'],\n",
       "  'train_frac': 0.75,\n",
       "  'use_mock_data': False,\n",
       "  'validation_frac': 0.33}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "068e4030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': 'd3d_data_ped_spec',\n",
       " 'executable': 'torch_learn.py',\n",
       " 'shallow_executable': 'learn.py',\n",
       " 'base_path': '/tigress',\n",
       " 'shot_list_dir': '/tigress/FRNN/shot_lists/',\n",
       " 'signal_prepath': ['/tigress/FRNN/signal_data_ipsip/',\n",
       "  '/tigress/FRNN/signal_data_new_nov2019/',\n",
       "  '/tigress/FRNN/signal_data_new_2020/',\n",
       "  '/tigress/FRNN/signal_data_new_2021/',\n",
       "  '/tigress/FRNN/signal_data_new_REAL_TIME/',\n",
       "  '/tigress/FRNN/signal_data/',\n",
       "  '/tigress/FRNN/signal_data_efit/'],\n",
       " 'global_normalizer_path': '/normalization/normalization_signal_group_184694441437167251751036554375425130447.npz',\n",
       " 'normalizer_path': './normalization/normalization_signal_group_184694441437167251751036554375425130447.npz',\n",
       " 'model_save_path': 'model_checkpoints',\n",
       " 'csvlog_save_path': 'csv_logs',\n",
       " 'results_prepath': 'results',\n",
       " 'saved_shotlist_path': '/tigress/processed_shotlists_torch',\n",
       " 'processed_prepath': '/tigress/../FRNN/rkube-temp/processed_shots_torch/signal_group_{h}',\n",
       " 'all_signals_dict': {'qmin': Minimum safety factor,\n",
       "  'n1_rms': n1 finite frequency signals,\n",
       "  'n2_rms_10': n2 finite frequency signals_10ms,\n",
       "  'n3_rms_10': n3 finite frequency signals_10ms,\n",
       "  'q95': q95 safety factor,\n",
       "  'li': internal inductance,\n",
       "  'ip': plasma current,\n",
       "  'betan': Normalized Beta,\n",
       "  'energy': stored energy,\n",
       "  'lm': Locked mode amplitude,\n",
       "  'dens': Plasma density,\n",
       "  'pradcore': Radiated Power Core,\n",
       "  'fs07': filterscope fs07,\n",
       "  'pradedge': Radiated Power Edge,\n",
       "  'pradtot': Radiated Power,\n",
       "  'pin': Input Power (beam for d3d),\n",
       "  'torquein': Input Beam Torque,\n",
       "  'neped': neped,\n",
       "  'teped': teped,\n",
       "  'newid': newid,\n",
       "  'peped': peped,\n",
       "  'tewid': tewid,\n",
       "  'iptarget': plasma current target,\n",
       "  'etemp_profile': Electron temperature profile,\n",
       "  'edens_profile': Electron density profile,\n",
       "  'mpi66m322d_spec_profile': mpi66m322d_spectrogram,\n",
       "  'qpsi_efitrt1': q profile efitrt1},\n",
       " 'shot_files': [machine: d3d\n",
       "  d3d data since shot 125500],\n",
       " 'shot_files_test': [],\n",
       " 'use_signals_dict': {'q95': q95 safety factor,\n",
       "  'qpsi_efitrt1': q profile efitrt1,\n",
       "  'fs07': filterscope fs07,\n",
       "  'neped': neped,\n",
       "  'peped': peped,\n",
       "  'newid': newid,\n",
       "  'teped': teped,\n",
       "  'tewid': tewid,\n",
       "  'ip': plasma current,\n",
       "  'lm': Locked mode amplitude,\n",
       "  'betan': Normalized Beta,\n",
       "  'energy': stored energy,\n",
       "  'dens': Plasma density,\n",
       "  'pradcore': Radiated Power Core,\n",
       "  'pradedge': Radiated Power Edge,\n",
       "  'pin': Input Power (beam for d3d),\n",
       "  'torquein': Input Beam Torque,\n",
       "  'etemp_profile': Electron temperature profile,\n",
       "  'edens_profile': Electron density profile,\n",
       "  'mpi66m322d_spec_profile': mpi66m322d_spectrogram,\n",
       "  'n1_rms': n1 finite frequency signals},\n",
       " 'use_signals': None,\n",
       " 'all_signals': None,\n",
       " 'shot_files_all': [machine: d3d\n",
       "  d3d data since shot 125500],\n",
       " 'all_machines': {d3d}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_conf[\"paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
