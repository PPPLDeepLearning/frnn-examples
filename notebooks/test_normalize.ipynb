{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feab3029",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83862c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# https://teddykoker.com/2020/12/dataloader/\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/rkube/repos/frnn-loader\")\n",
    "\n",
    "from os.path import join\n",
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from frnn_loader.backends.fetchers import fetcher_d3d_v1\n",
    "from frnn_loader.backends.backend_hdf5 import backend_hdf5\n",
    "from frnn_loader.primitives.filters import filter_ip_thresh\n",
    "from frnn_loader.primitives.resamplers import resampler_causal\n",
    "from frnn_loader.primitives.signal import signal_0d\n",
    "from frnn_loader.primitives.normalizers import mean_std_normalizer\n",
    "from frnn_loader.loaders.frnn_dataset_disk import shot_dataset_disk\n",
    "from frnn_loader.loaders.frnn_multi_dataset import frnn_multi_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2464bbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Construct a dataset for FRNN training.\\n\\nPredictive machine learning models are trained on datasets. These dataset\\nconsist of a suite of measurements taken on a set of shots.\\n\\nDeep neural networks are trained on pre-processed and normalized data.\\nPre-processing includes:\\n- Resampling of the measurements onto a common time-base\\n- Construction of target variables, such as time-to-disruption or time-to-ELM\\n- Signal clipping\\n- Calculating and applying normalization\\n\\nNormalization means the transformation of signals into order unity quantities. Common ways\\nto do this is by a Z-score transformation (subtract mean, divide by std dev.), min/max normalizer,\\netc.\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Construct a dataset for FRNN training.\n",
    "\n",
    "Predictive machine learning models are trained on datasets. These dataset\n",
    "consist of a suite of measurements taken on a set of shots.\n",
    "\n",
    "Deep neural networks are trained on pre-processed and normalized data.\n",
    "Pre-processing includes:\n",
    "- Resampling of the measurements onto a common time-base\n",
    "- Construction of target variables, such as time-to-disruption or time-to-ELM\n",
    "- Signal clipping\n",
    "- Calculating and applying normalization\n",
    "\n",
    "Normalization means the transformation of signals into order unity quantities. Common ways\n",
    "to do this is by a Z-score transformation (subtract mean, divide by std dev.), min/max normalizer,\n",
    "etc.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "061fad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where all project data files are to be stored\n",
    "proj_dir = \"/projects/FRNN/frnn_loader\"\n",
    "\n",
    "# 1/ Describe the dataset\n",
    "predictor_tags = [\n",
    "    \"q95\",\n",
    "    \"efsli\",\n",
    "    \"ipspr15V\",\n",
    "    \"efsbetan\",\n",
    "    \"efswmhd\",\n",
    "    \"dusbradial\",\n",
    "    \"dssdenest\",\n",
    "    \"pradcore\",\n",
    "    \"pradedge\",\n",
    "    \"bmspinj\",\n",
    "    \"bmstinj\",\n",
    "    \"ipsiptargt\",\n",
    "    \"ipeecoil\",\n",
    "]\n",
    "predictor_list = [signal_0d(tag) for tag in predictor_tags]\n",
    "\n",
    "# Contains a list of shots that are non-disruptive\n",
    "shotlist_clear = \"d3d_clear_100.txt\"\n",
    "# Contains a list of shots that are disruptive\n",
    "shotlist_disrupt = \"d3d_disrupt_100.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5d7cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the filter we use to crimp the shot times\n",
    "ip_filter = filter_ip_thresh(0.2)\n",
    "signal_ip = signal_0d(\"ipspr15V\")\n",
    "my_backend = backend_hdf5(proj_dir)\n",
    "my_fetcher = fetcher_d3d_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61e7bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots = 5\n",
    "shotdict = {}\n",
    "\n",
    "i = 0\n",
    "with open(join(proj_dir, \"..\", \"shot_lists\", shotlist_clear), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "\n",
    "        # Run the Ip filter over the current shot\n",
    "        tb, data = my_backend.load(signal_ip.info, shotnr)\n",
    "        tmin, tmax = ip_filter(tb, data)\n",
    "        shotdict.update(\n",
    "            {\n",
    "                shotnr: {\n",
    "                    \"tmin\": tmin,\n",
    "                    \"tmax\": tmax,\n",
    "                    \"is_disruptive\": False,\n",
    "                    \"t_disrupt\": -1.0,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        i += 1\n",
    "        if i >= num_shots:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba1d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "with open(join(proj_dir, \"..\", \"shot_lists\", shotlist_disrupt), \"r\") as fp:\n",
    "    for line in fp.readlines():\n",
    "        # Convert shotnr to int and ttd to float\n",
    "        shotnr, ttd = [trf(val) for trf, val in zip([int, float], line.split())]\n",
    "        # ttd is given in seconds in the text files. Convert it to milliseconds\n",
    "        ttd = ttd * 1e3\n",
    "        shotdict.update(\n",
    "            {\n",
    "                shotnr: {\n",
    "                    \"tmin\": tmin,\n",
    "                    \"tmax\": ttd,\n",
    "                    \"is_disruptive\": True,\n",
    "                    \"t_disrupt\": ttd,\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        i += 1\n",
    "        if i >= num_shots:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bc541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tmin': 37.75, 'tmax': 6233.25, 'is_disruptive': False, 't_disrupt': -1.0}\n",
      "{'tmin': 30.5, 'tmax': 6455.25, 'is_disruptive': False, 't_disrupt': -1.0}\n",
      "{'tmin': 34.0, 'tmax': 6445.25, 'is_disruptive': False, 't_disrupt': -1.0}\n",
      "{'tmin': 37.0, 'tmax': 6842.25, 'is_disruptive': False, 't_disrupt': -1.0}\n",
      "{'tmin': 37.5, 'tmax': 6245.0, 'is_disruptive': False, 't_disrupt': -1.0}\n",
      "{'tmin': 37.5, 'tmax': 5073.5, 'is_disruptive': True, 't_disrupt': 5073.5}\n",
      "{'tmin': 37.5, 'tmax': 2159.0, 'is_disruptive': True, 't_disrupt': 2159.0}\n",
      "{'tmin': 37.5, 'tmax': 5269.0, 'is_disruptive': True, 't_disrupt': 5269.0}\n",
      "{'tmin': 37.5, 'tmax': 7088.0, 'is_disruptive': True, 't_disrupt': 7088.0}\n",
      "{'tmin': 37.5, 'tmax': 3478.5, 'is_disruptive': True, 't_disrupt': 3478.5}\n"
     ]
    }
   ],
   "source": [
    "for k in shotdict.keys():\n",
    "    print(shotdict[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "636de3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "#\n",
    "# Next we create a list of datasets for all shots.\n",
    "# The shots are cut to the time intervals defined by tmin and tmax\n",
    "# A normalizer is calculated from these datasets.\n",
    "# After the normalizer has been calculated the hdf5 files generated by\n",
    "# these dataset are to be deleted using ds.delete_data_file\n",
    "\n",
    "dset_unnormalized_list = []\n",
    "for shotnr in shotdict.keys():\n",
    "\n",
    "    # Resample all signals over the valid intervals\n",
    "    my_resampler = resampler_causal(0.0, shotdict[shotnr][\"tmax\"], 1.0)\n",
    "\n",
    "    ds = shot_dataset_disk(\n",
    "        shotnr,\n",
    "        predictors=predictor_list,\n",
    "        resampler=my_resampler,\n",
    "        backend_file=my_backend,\n",
    "        fetcher=my_fetcher,\n",
    "        root=proj_dir,\n",
    "        download=True,\n",
    "        normalizer=None,\n",
    "        is_disruptive=shotdict[shotnr][\"is_disruptive\"],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    dset_unnormalized_list.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b03bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/FRNN/frnn_loader/d5t4j1ka.h5'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_unnormalized_list[0].tmp_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a9cf6005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6.2881e+00,  1.0096e+00,  1.7226e+00,  1.6998e+00,  5.6891e+05,\n",
      "         9.0436e-01,  3.2198e+00,  1.5518e-03,  1.3113e-03,  5.0626e+03,\n",
      "         4.0367e+00,  1.7478e+00, -2.8650e-02])\n",
      "tensor([1.8086e+00, 3.4762e-01, 4.5560e-01, 1.0277e+00, 3.6443e+05, 1.0497e+00,\n",
      "        1.3093e+00, 1.9447e-03, 1.0103e-03, 3.3218e+03, 2.7402e+00, 4.6416e-01,\n",
      "        1.1235e-01])\n"
     ]
    }
   ],
   "source": [
    "#########################################################################################################\n",
    "#\n",
    "# With all datasets cropped to the correct time in place we continue by calculating the normalization.\n",
    "# Do this using multi-processing\n",
    "my_normalizer = mean_std_normalizer()\n",
    "my_normalizer.fit(dset_unnormalized_list)\n",
    "\n",
    "print(my_normalizer.mean_all)\n",
    "print(my_normalizer.std_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a001835c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6234, 13]) tensor([ 6.2397e+00,  9.7653e-01,  1.7384e+00,  1.8166e+00,  6.2798e+05,\n",
      "         8.9967e-01,  3.0376e+00,  1.8857e-03,  1.3896e-03,  5.6089e+03,\n",
      "         4.3848e+00,  1.7696e+00, -3.5331e-02]) tensor([1.4428e+00, 3.8160e-01, 4.3369e-01, 1.0206e+00, 3.7188e+05, 9.9816e-01,\n",
      "        1.0748e+00, 1.6551e-03, 9.2308e-04, 3.3695e+03, 2.6507e+00, 4.0958e-01,\n",
      "        8.1703e-02])\n",
      "torch.Size([6456, 13]) tensor([ 6.3304e+00,  9.5908e-01,  1.7055e+00,  1.7223e+00,  5.9248e+05,\n",
      "         1.0999e+00,  3.5379e+00,  2.2489e-03,  1.1336e-03,  6.2639e+03,\n",
      "         5.0638e+00,  1.7213e+00, -1.9438e-02]) tensor([1.3597e+00, 3.2436e-01, 4.5833e-01, 1.1209e+00, 3.8976e+05, 9.6813e-01,\n",
      "        1.4991e+00, 2.3117e-03, 7.9456e-04, 4.3591e+03, 3.5988e+00, 4.7794e-01,\n",
      "        3.4468e-02])\n",
      "torch.Size([6446, 13]) tensor([ 6.2318e+00,  9.8198e-01,  1.7139e+00,  1.7978e+00,  6.1599e+05,\n",
      "         1.0388e+00,  3.2425e+00,  1.9478e-03,  1.2806e-03,  6.1516e+03,\n",
      "         4.9985e+00,  1.7236e+00, -1.3393e-02]) tensor([1.3552e+00, 3.8591e-01, 4.5194e-01, 1.2057e+00, 4.1085e+05, 9.5314e-01,\n",
      "        1.1986e+00, 2.1408e-03, 8.8489e-04, 4.2679e+03, 3.5222e+00, 4.7465e-01,\n",
      "        3.0447e-02])\n",
      "torch.Size([6843, 13]) tensor([6.3808e+00, 9.8987e-01, 1.6348e+00, 1.8821e+00, 6.4496e+05, 1.1380e+00,\n",
      "        3.0580e+00, 1.0806e-03, 1.6370e-03, 4.6731e+03, 3.7096e+00, 1.6236e+00,\n",
      "        7.6094e-03]) tensor([1.5047e+00, 4.4342e-01, 5.4785e-01, 1.2397e+00, 4.3246e+05, 1.5773e+00,\n",
      "        1.2309e+00, 6.7761e-04, 1.2218e-03, 3.1081e+03, 2.5240e+00, 6.1181e-01,\n",
      "        7.6807e-02])\n",
      "torch.Size([6245, 13]) tensor([ 6.1641e+00,  1.1944e+00,  1.6808e+00,  1.2150e+00,  4.1039e+05,\n",
      "         9.5108e-01,  2.4588e+00,  9.5036e-04,  1.1430e-03,  3.5103e+03,\n",
      "         2.7994e+00,  1.6978e+00, -2.0990e-02]) tensor([1.6885e+00, 4.4112e-01, 4.7270e-01, 9.8208e-01, 3.3363e+05, 1.1553e+00,\n",
      "        1.1104e+00, 6.7137e-04, 8.5966e-04, 2.5258e+03, 2.0657e+00, 4.9898e-01,\n",
      "        3.3547e-02])\n",
      "torch.Size([5074, 13]) tensor([ 6.2922e+00,  9.7227e-01,  1.8208e+00,  2.0668e+00,  7.1978e+05,\n",
      "         5.6795e-01,  3.3694e+00,  1.5282e-03,  1.5209e-03,  5.6588e+03,\n",
      "         4.5078e+00,  1.8320e+00, -1.5882e-02]) tensor([1.4622e+00, 1.0653e-01, 3.3470e-01, 9.7854e-01, 3.5812e+05, 4.6422e-01,\n",
      "        1.1215e+00, 1.5047e-03, 9.2717e-04, 2.4952e+03, 2.0612e+00, 3.5747e-01,\n",
      "        3.2094e-02])\n",
      "torch.Size([2159, 13]) tensor([ 7.2296e+00,  1.1973e+00,  1.5904e+00,  1.3148e+00,  4.2953e+05,\n",
      "         6.7528e-01,  2.7745e+00,  1.2043e-03,  8.4337e-04,  3.4899e+03,\n",
      "         2.6735e+00,  1.6480e+00, -6.4315e-02]) tensor([3.5829e+00, 3.4313e-01, 5.3832e-01, 9.6082e-01, 3.2290e+05, 6.2542e-01,\n",
      "        1.4761e+00, 2.5453e-03, 8.8835e-04, 2.6500e+03, 2.1383e+00, 5.2571e-01,\n",
      "        8.4934e-02])\n",
      "torch.Size([5269, 13]) tensor([ 6.1164e+00,  1.0783e+00,  1.7958e+00,  1.8344e+00,  6.2504e+05,\n",
      "         1.0442e+00,  3.6635e+00,  1.8161e-03,  1.4574e-03,  5.5831e+03,\n",
      "         4.4408e+00,  1.8324e+00, -4.0057e-02]) tensor([1.1194e+00, 2.2931e-01, 3.6867e-01, 7.1947e-01, 2.7216e+05, 5.5315e-01,\n",
      "        1.3123e+00, 1.6171e-03, 8.1443e-04, 2.4242e+03, 2.0054e+00, 3.6990e-01,\n",
      "        4.1786e-02])\n",
      "torch.Size([7088, 13]) tensor([ 5.4926e+00,  9.1756e-01,  1.8842e+00,  1.7602e+00,  5.5310e+05,\n",
      "         5.5047e-01,  3.5239e+00,  8.7479e-04,  1.8275e-03,  5.2975e+03,\n",
      "         4.3953e+00,  1.8883e+00, -4.1001e-03]) tensor([1.1960e+00, 2.4167e-01, 3.5372e-01, 8.0211e-01, 2.8397e+05, 5.4294e-01,\n",
      "        1.0131e+00, 3.8598e-04, 1.1545e-03, 3.4127e+03, 2.9373e+00, 3.4894e-01,\n",
      "        4.8895e-02])\n",
      "torch.Size([3479, 13]) tensor([ 6.4033e+00,  8.2892e-01,  1.6615e+00,  1.5882e+00,  4.6979e+05,\n",
      "         1.0782e+00,  3.5317e+00,  1.9817e-03,  8.8031e-04,  4.3892e+03,\n",
      "         3.3939e+00,  1.7421e+00, -8.0603e-02]) tensor([1.6076e+00, 2.3700e-01, 4.6359e-01, 8.1161e-01, 3.0203e+05, 1.6418e+00,\n",
      "        1.4235e+00, 3.2516e-03, 1.0755e-03, 2.4260e+03, 2.0201e+00, 4.2863e-01,\n",
      "        3.0241e-01])\n"
     ]
    }
   ],
   "source": [
    "# Print mean and standard deviation for unnormalized datasets \n",
    "for ds in dset_unnormalized_list:\n",
    "    print(ds[:][0].shape, ds[:][0].mean(axis=0), ds[:][0].std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "20f2490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167475\n",
      "167481\n",
      "167482\n",
      "167483\n",
      "167484\n",
      "167480\n",
      "167487\n",
      "167488\n",
      "167492\n",
      "167494\n"
     ]
    }
   ],
   "source": [
    "# With a normalizer at hand, we can now safely delete the datafiles from the\n",
    "# un-normalized shots.\n",
    "# Then re-instantiate the datasets using the trained normalizer\n",
    "dset_normalized_list = []\n",
    "for shotnr in shotdict.keys():\n",
    "    print(shotnr)\n",
    "\n",
    "    # Resample all signals over the valid intervals\n",
    "    my_resampler = resampler_causal(0.0, shotdict[shotnr][\"tmax\"], 1.0)\n",
    "\n",
    "    ds = shot_dataset_disk(\n",
    "        shotnr,\n",
    "        predictors=predictor_list,\n",
    "        resampler=my_resampler,\n",
    "        backend_file=my_backend,\n",
    "        fetcher=my_fetcher,\n",
    "        root=proj_dir,\n",
    "        download=True,\n",
    "        normalizer=my_normalizer,\n",
    "        is_disruptive=shotdict[shotnr][\"is_disruptive\"],\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "\n",
    "    dset_normalized_list.append(ds)\n",
    "\n",
    "dset_all = frnn_multi_dataset(dset_normalized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82621ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a31e8f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.2513, -0.9522, -3.7854,  ..., -1.4732, -3.7656, -0.0968],\n",
       "         [ 3.2513, -0.9522, -3.7825,  ..., -1.4732, -3.7656,  0.0156],\n",
       "         [ 3.2513, -0.9522, -3.7672,  ..., -1.4732, -3.7656,  0.0483],\n",
       "         ...,\n",
       "         [ 0.7562, -2.9044, -3.1938,  ..., -1.4732, -3.1017, -0.1069],\n",
       "         [ 0.7562, -2.9044, -3.2420,  ..., -1.4732, -3.1023, -0.2999],\n",
       "         [ 0.7562, -2.9044, -3.2868,  ..., -1.4732, -3.1030, -0.4787]]),\n",
       " tensor([[1.0043],\n",
       "         [1.0043],\n",
       "         [1.0043],\n",
       "         ...,\n",
       "         [1.0043],\n",
       "         [1.0043],\n",
       "         [1.0043]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_all[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e558bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a196474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "27a06a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6234, 13]) tensor([-0.0267, -0.0952,  0.0347,  0.1136,  0.1621, -0.0045, -0.1391,  0.1717,\n",
      "         0.0775,  0.1645,  0.1270,  0.0469, -0.0595]) tensor([0.7978, 1.0978, 0.9519, 0.9931, 1.0204, 0.9509, 0.8209, 0.8511, 0.9136,\n",
      "        1.0144, 0.9674, 0.8824, 0.7272])\n",
      "torch.Size([6456, 13]) tensor([ 0.0234, -0.1454, -0.0376,  0.0219,  0.0647,  0.1862,  0.2429,  0.3585,\n",
      "        -0.1759,  0.3616,  0.3748, -0.0572,  0.0820]) tensor([0.7518, 0.9331, 1.0060, 1.0907, 1.0695, 0.9223, 1.1449, 1.1887, 0.7864,\n",
      "        1.3123, 1.3134, 1.0297, 0.3068])\n",
      "torch.Size([6446, 13]) tensor([-0.0311, -0.0795, -0.0192,  0.0953,  0.1292,  0.1281,  0.0173,  0.2036,\n",
      "        -0.0305,  0.3278,  0.3510, -0.0523,  0.1358]) tensor([0.7493, 1.1101, 0.9920, 1.1733, 1.1274, 0.9080, 0.9154, 1.1008, 0.8759,\n",
      "        1.2848, 1.2854, 1.0226, 0.2710])\n",
      "torch.Size([6843, 13]) tensor([ 0.0513, -0.0568, -0.1926,  0.1774,  0.2087,  0.2226, -0.1236, -0.2423,\n",
      "         0.3224, -0.1173, -0.1194, -0.2677,  0.3227]) tensor([0.8320, 1.2756, 1.2025, 1.2064, 1.1867, 1.5026, 0.9401, 0.3484, 1.2093,\n",
      "        0.9357, 0.9211, 1.3181, 0.6837])\n",
      "torch.Size([6245, 13]) tensor([-0.0685,  0.5314, -0.0918, -0.4718, -0.4350,  0.0445, -0.5812, -0.3093,\n",
      "        -0.1666, -0.4673, -0.4516, -0.1079,  0.0682]) tensor([0.9336, 1.2690, 1.0375, 0.9556, 0.9155, 1.1005, 0.8481, 0.3452, 0.8509,\n",
      "        0.7604, 0.7538, 1.0750, 0.2986])\n",
      "torch.Size([5074, 13]) tensor([ 0.0023, -0.1074,  0.2156,  0.3571,  0.4140, -0.3205,  0.1143, -0.0122,\n",
      "         0.2074,  0.1795,  0.1719,  0.1813,  0.1136]) tensor([0.8085, 0.3065, 0.7346, 0.9522, 0.9827, 0.4422, 0.8565, 0.7737, 0.9177,\n",
      "        0.7511, 0.7522, 0.7701, 0.2857])\n",
      "torch.Size([2159, 13]) tensor([ 0.5206,  0.5399, -0.2903, -0.3747, -0.3824, -0.2182, -0.3401, -0.1787,\n",
      "        -0.4632, -0.4734, -0.4975, -0.2151, -0.3175]) tensor([1.9811, 0.9871, 1.1816, 0.9350, 0.8860, 0.5958, 1.1274, 1.3088, 0.8793,\n",
      "        0.7977, 0.7803, 1.1326, 0.7560])\n",
      "torch.Size([5269, 13]) tensor([-0.0950,  0.1975,  0.1606,  0.1310,  0.1540,  0.1332,  0.3389,  0.1359,\n",
      "         0.1445,  0.1567,  0.1475,  0.1822, -0.1015]) tensor([0.6190, 0.6597, 0.8092, 0.7001, 0.7468, 0.5269, 1.0023, 0.8315, 0.8061,\n",
      "        0.7298, 0.7319, 0.7969, 0.3719])\n",
      "torch.Size([7088, 13]) tensor([-0.4398, -0.2648,  0.3547,  0.0587, -0.0434, -0.3371,  0.2323, -0.3481,\n",
      "         0.5109,  0.0707,  0.1308,  0.3026,  0.2185]) tensor([0.6613, 0.6952, 0.7764, 0.7805, 0.7792, 0.5172, 0.7738, 0.1985, 1.1427,\n",
      "        1.0273, 1.0720, 0.7518, 0.4352])\n",
      "torch.Size([3479, 13]) tensor([ 0.0637, -0.5198, -0.1341, -0.1086, -0.2720,  0.1656,  0.2382,  0.2210,\n",
      "        -0.4266, -0.2027, -0.2346, -0.0124, -0.4624]) tensor([0.8889, 0.6818, 1.0175, 0.7898, 0.8288, 1.5641, 1.0872, 1.6720, 1.0645,\n",
      "        0.7303, 0.7372, 0.9235, 2.6918])\n"
     ]
    }
   ],
   "source": [
    "# Verify that the returned data is about zero mean and order unity std deviation\n",
    "for ds in dset_all:\n",
    "    print(ds[:][0].shape, ds[:][0].mean(axis=0), ds[:][0].std(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb283f",
   "metadata": {},
   "source": [
    "## Plot results of normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49543cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    fig = plt.figure(figsize=(8, 4))\n",
    "\n",
    "    ax_u = fig.add_axes([0.1, 0.1, 0.35, 0.7])\n",
    "    ax_n = fig.add_axes([0.5, 0.1, 0.35, 0.7])\n",
    "\n",
    "    fig.text(0.5, 0.95, dset_unnormalized_list[0].predictors[i], ha=\"center\")\n",
    "\n",
    "    ax_u.set_title(\"Unnormalized\")\n",
    "    for ds in dset_unnormalized_list:\n",
    "        label = f\"{ds.shotnr}: Disrupts: {ds.is_disruptive}\"\n",
    "        ax_u.plot(ds[:][0][:, i], label=label)\n",
    "\n",
    "    ax_n.set_title(\"Normalized\")\n",
    "    for ds in dset_all:\n",
    "        label = f\"{ds.shotnr}: Disrupts: {ds.is_disruptive}\"\n",
    "        ax_n.plot(ds[:][0][:, i], label=label)\n",
    "    ax_n.legend(loc=\"upper right\", bbox_to_anchor=(1.85, 1), borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14123ba8",
   "metadata": {},
   "source": [
    "# Paths\n",
    "\n",
    "The basis path where all data is searched for is given by conf[\"paths\"][\"fs_path\"]. \n",
    "\n",
    "Directories that are searched for signals are given by conf[\"paths\"][\"signal_prepath\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0976f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e4030",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_conf[\"paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
